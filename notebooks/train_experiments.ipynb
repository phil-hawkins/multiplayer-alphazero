{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import Module, Linear, BatchNorm1d, ReLU, ModuleList, Dropout\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from time import time\n",
    "from tqdm import trange\n",
    "from math import inf\n",
    "import joblib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from games.vortex import Vortex_5_mctspt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "td1 = torch.load(os.path.join(\"../checkpoints/Vortex_5_mctspt-VorNetBN\", \"training.data\"))\n",
    "td2 = torch.load(os.path.join(\"../checkpoints/Vortex_5_mctspt-VorNetBN_1\", \"training.data\"))\n",
    "\n",
    "td = {}\n",
    "td['training_data'] = np.concatenate([td1['training_data'],td2['training_data']])\n",
    "\n",
    "torch.save(td, \"../checkpoints/train_ex/training.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayoutDataset():\n",
    "    def __init__(self, data):\n",
    "        super(PlayoutDataset, self).__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get length of dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of vertices in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    @classmethod    \n",
    "    def get_train_val_ds(cls, data_dir, train_split=0.9):\n",
    "        \"\"\"Splits the data randomly and creates train and validation datasets\n",
    "        \"\"\"       \n",
    "        data_checkpoint = torch.load(os.path.join(data_dir, \"training.data\"))\n",
    "        data = data_checkpoint['training_data']\n",
    "        data_idx = np.arange(len(data))\n",
    "        np.random.shuffle(data_idx)\n",
    "        val_start_idx = int(len(data) * train_split)\n",
    "        train_idx, val_idx = data_idx[:val_start_idx], data_idx[val_start_idx:]\n",
    "        train_data, val_data = data[train_idx], data[val_idx]\n",
    "\n",
    "        # fix any data leakage\n",
    "        hashes = set()\n",
    "        for ex in train_data:\n",
    "            hashes.add(ex[0].tostring())\n",
    "        val_data = np.array([ex for ex in val_data if ex[0].tostring() not in hashes])\n",
    "\n",
    "        return cls(train_data), cls(val_data)\n",
    "\n",
    "class PlayoutLoader():\n",
    "    def __init__(self, dataset, batch_size, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.idx = np.arange(len(dataset))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.idx), self.batch_size):\n",
    "            idx = self.idx[i:i+self.batch_size]\n",
    "            # make sure there is more than 1 example in the batch\n",
    "            if len(idx) > 1:\n",
    "                yield self.dataset.data[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0.\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.avg:.2e}'\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, in_features, hidden_dims, hidden_layers, out_features, dropout):\n",
    "        super().__init__()\n",
    "        self._mlist = ModuleList([\n",
    "            Linear(in_features, hidden_dims),\n",
    "            ReLU()\n",
    "        ])\n",
    "        for _ in range(hidden_layers):\n",
    "            self._mlist.append(Linear(hidden_dims, hidden_dims))\n",
    "            self._mlist.append(BatchNorm1d(hidden_dims))\n",
    "            self._mlist.append(ReLU())\n",
    "            self._mlist.append(Dropout(p=dropout))\n",
    "        self._mlist.append(Linear(hidden_dims, out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self._mlist:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class VorNet(Module):\n",
    "    def __init__(self, input_shape, p_shape, v_shape, policy_layers, policy_dim, value_layers, value_dim, dropout):\n",
    "        super(VorNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.p_shape = p_shape\n",
    "        self.v_shape = v_shape\n",
    "        B, F = input_shape\n",
    "\n",
    "        self.input_bn = BatchNorm1d(F)\n",
    "        self.policy_head = MLP(F, policy_dim, policy_layers, 1, dropout)\n",
    "        self.value_head = MLP(4*F, value_dim, value_layers, np.prod(self.v_shape), dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, F = x.shape\n",
    "\n",
    "        x = self.input_bn(x.view(B*N, F)).view(B, N, F)\n",
    "\n",
    "        side_nodes = x[:, -4:, :]\n",
    "        x = x.view(B*N, F)\n",
    "        p = self.policy_head(x)\n",
    "        p = p.view(B, np.prod(self.p_shape))\n",
    "        \n",
    "        side_nodes = side_nodes.view(B, 4*F)\n",
    "        v = self.value_head(side_nodes).tanh()\n",
    "\n",
    "        return p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_dist(s, logits, log_softmax=False):\n",
    "    mask = torch.from_numpy(game.get_available_actions(s).astype(np.uint8)).bool()\n",
    "    mask = mask.cuda()\n",
    "    selection = torch.masked_select(logits, mask)\n",
    "    dist = torch.nn.functional.log_softmax(selection, dim=-1)\n",
    "    if log_softmax:\n",
    "        return dist\n",
    "    return torch.exp(dist)\n",
    "\n",
    "def calc_loss(states, prediction, target):\n",
    "    batch_size = len(states)\n",
    "    p_pred, v_pred = prediction\n",
    "    p_gt, v_gt = target\n",
    "    v_gt = torch.from_numpy(v_gt.astype(np.float32))\n",
    "    v_gt = v_gt.cuda()\n",
    "    v_loss = ((v_pred - v_gt)**2).sum() # Mean squared error\n",
    "    p_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        gt = torch.from_numpy(p_gt[i].astype(np.float32))\n",
    "        gt = gt.cuda()\n",
    "        s = states[i]\n",
    "        logits = p_pred[i]\n",
    "        pred = get_valid_dist(s, logits, log_softmax=True)\n",
    "        p_loss += -torch.sum(gt*pred)\n",
    "    return p_loss + v_loss\n",
    "\n",
    "\n",
    "def get_batch_states(batch):\n",
    "    states = np.stack(batch[:,0])\n",
    "    nn_states = [s.nn_attr for s in states]\n",
    "    nn_states = np.stack(nn_states)\n",
    "        \n",
    "    return nn_states, states\n",
    "\n",
    "def train_step(batch, model, optimizer):\n",
    "    model.train()\n",
    "    nn_states, states = get_batch_states(batch)\n",
    "    x = torch.from_numpy(nn_states)\n",
    "    p_pred, v_pred = model(x)\n",
    "    p_gt, v_gt = batch[:,1], np.stack(batch[:,2])\n",
    "    loss = calc_loss(states, (p_pred, v_pred), (p_gt, v_gt))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(batch, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        nn_states, states = get_batch_states(batch)\n",
    "        x = torch.from_numpy(nn_states)\n",
    "        p_pred, v_pred = model(x)\n",
    "        p_gt, v_gt = batch[:,1], np.stack(batch[:,2])\n",
    "        loss = calc_loss(states, (p_pred, v_pred), (p_gt, v_gt))\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded\n",
      "  34991 train examples\n",
      "  3236 validation examples\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR=\"../checkpoints/train_ex\"\n",
    "EPOCHS=5\n",
    "LR=1e-3\n",
    "WEIGHT_DECAY=1e-4\n",
    "\n",
    "train_ds, val_ds = PlayoutDataset.get_train_val_ds(data_dir=DATA_DIR)\n",
    "print(\"Training data loaded\")\n",
    "print(\"  {} train examples\".format(train_ds.__len__()))\n",
    "print(\"  {} validation examples\".format(val_ds.__len__()))\n",
    "game = Vortex_5_mctspt()\n",
    "input_shape = game.get_initial_state().shape\n",
    "p_shape = game.get_available_actions(game.get_initial_state()).shape\n",
    "v_shape = (game.get_num_players(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = VorNet(\n",
    "        input_shape, \n",
    "        p_shape, \n",
    "        v_shape,\n",
    "        10, #trial.suggest_int(\"policy_layers\", 1, 15),\n",
    "        trial.suggest_int(\"policy_dim\", 100, 1000),\n",
    "        10, #trial.suggest_int(\"value_layers\", 8, 20),\n",
    "        trial.suggest_int(\"value_dim\", 100, 1000),\n",
    "        trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    )\n",
    "    model = model.to('cuda')\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # weight_decay = lr/10\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", LR/100, LR/2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n",
    "\n",
    "    # get the data loaders\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 2, 32)\n",
    "\n",
    "    # Training of the model.\n",
    "    best_loss = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loader = PlayoutLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = PlayoutLoader(dataset=val_ds, batch_size=batch_size)\n",
    "        val_loss = AverageMeter()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            train_step(batch, model, optimizer)\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            loss = val_step(batch, model)\n",
    "            val_loss.update(loss)\n",
    "\n",
    "        trial.report(val_loss.avg, epoch)\n",
    "        best_loss = val_loss.avg if best_loss is None else min(best_loss, val_loss.avg)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-13 09:17:34,856]\u001b[0m A new study created in memory with name: VorNet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#study = optuna.create_study(study_name=\"VorNet\", direction=\"minimize\")\n",
    "study = joblib.load(\"../checkpoints/train_ex/study.pkl\")\n",
    "print(\"Best trial until now:\")\n",
    "print(\" Value: \", study.best_trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-13 09:36:57,938]\u001b[0m Trial 0 finished with value: 21.14519720510067 and parameters: {'policy_dim': 681, 'value_dim': 971, 'dropout': 0.4642877789109309, 'weight_decay': 0.0004569724962396698, 'batch_size': 7}. Best is trial 0 with value: 21.14519720510067.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 09:44:17,200]\u001b[0m Trial 1 finished with value: 57.22344035990754 and parameters: {'policy_dim': 857, 'value_dim': 206, 'dropout': 0.4364890890951273, 'weight_decay': 3.8759554354336184e-05, 'batch_size': 19}. Best is trial 0 with value: 21.14519720510067.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 09:56:33,092]\u001b[0m Trial 2 finished with value: 36.41320186191135 and parameters: {'policy_dim': 188, 'value_dim': 981, 'dropout': 0.41915752678968177, 'weight_decay': 0.0004519333337300498, 'batch_size': 12}. Best is trial 0 with value: 21.14519720510067.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 10:02:44,428]\u001b[0m Trial 3 finished with value: 73.01789805094401 and parameters: {'policy_dim': 275, 'value_dim': 733, 'dropout': 0.4929411225997846, 'weight_decay': 0.00041426223595958036, 'batch_size': 24}. Best is trial 0 with value: 21.14519720510067.\u001b[0m\n",
      "\u001b[33m[W 2022-01-13 10:02:44,513]\u001b[0m Trial 4 failed because of the following error: ValueError('Caught ValueError in replica 1 on device 1.\\nOriginal Traceback (most recent call last):\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\\n    output = module(*input, **kwargs)\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 43, in forward\\n    v = self.value_head(side_nodes).tanh()\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 17, in forward\\n    x = layer(x)\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\\n    return F.batch_norm(\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2280, in batch_norm\\n    _verify_batch_size(input.size())\\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2248, in _verify_batch_size\\n    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\\nValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 959])\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1819343/3466384885.py\", line 32, in objective\n",
      "    train_step(batch, model, optimizer)\n",
      "  File \"/tmp/ipykernel_1819343/2984829129.py\", line 39, in train_step\n",
      "    p_pred, v_pred = model(x)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\", line 178, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 86, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "ValueError: Caught ValueError in replica 1 on device 1.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1819343/980464015.py\", line 43, in forward\n",
      "    v = self.value_head(side_nodes).tanh()\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1819343/980464015.py\", line 17, in forward\n",
      "    x = layer(x)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2280, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2248, in _verify_batch_size\n",
      "    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 959])\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 43, in forward\n    v = self.value_head(side_nodes).tanh()\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 17, in forward\n    x = layer(x)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n    return F.batch_norm(\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2280, in batch_norm\n    _verify_batch_size(input.size())\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2248, in _verify_batch_size\n    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\nValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 959])\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1819343/594029038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1819343/3466384885.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1819343/2984829129.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch, model, optimizer)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mp_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 43, in forward\n    v = self.value_head(side_nodes).tanh()\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_1819343/980464015.py\", line 17, in forward\n    x = layer(x)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n    return F.batch_norm(\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2280, in batch_norm\n    _verify_batch_size(input.size())\n  File \"/home/philh/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/functional.py\", line 2248, in _verify_batch_size\n    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\nValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 959])\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optuna.visualization.matplotlib.plot_contour(study, params=['batch_size', 'lr'])\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../checkpoints/train_ex/study.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, os.path.join(DATA_DIR, \"study.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7574f5d857af8f1e8f26ae1ddb33f0e7cd225dc65e7450a2fdad37c59c700f3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('maz': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
