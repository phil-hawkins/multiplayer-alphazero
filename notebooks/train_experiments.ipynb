{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import Module, Linear, BatchNorm1d, ReLU, ModuleList, Dropout\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from time import time\n",
    "from tqdm import trange\n",
    "from math import inf\n",
    "import joblib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from games.vortex import Vortex_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td1 = torch.load(os.path.join(\"../checkpoints/Vortex_5_mctspt-VorNetBN\", \"training.data\"))\n",
    "# td2 = torch.load(os.path.join(\"../checkpoints/Vortex_5_mctspt-VorNetBN_1\", \"training.data\"))\n",
    "\n",
    "# td = {}\n",
    "# td['training_data'] = np.concatenate([td1['training_data'],td2['training_data']])\n",
    "\n",
    "# torch.save(td, \"../checkpoints/train_ex/training.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayoutDataset():\n",
    "    def __init__(self, data):\n",
    "        super(PlayoutDataset, self).__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get length of dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of vertices in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    @classmethod    \n",
    "    def get_train_val_ds(cls, data_dir, train_split=0.9):\n",
    "        \"\"\"Splits the data randomly and creates train and validation datasets\n",
    "        \"\"\"       \n",
    "        data_checkpoint = torch.load(os.path.join(data_dir, \"training.data\"))\n",
    "        data = data_checkpoint['training_data']\n",
    "        data_idx = np.arange(len(data))\n",
    "        np.random.shuffle(data_idx)\n",
    "        val_start_idx = int(len(data) * train_split)\n",
    "        train_idx, val_idx = data_idx[:val_start_idx], data_idx[val_start_idx:]\n",
    "        train_data, val_data = data[train_idx], data[val_idx]\n",
    "\n",
    "        # fix any data leakage\n",
    "        hashes = set()\n",
    "        for ex in train_data:\n",
    "            hashes.add(ex[0].tostring())\n",
    "        val_data = np.array([ex for ex in val_data if ex[0].tostring() not in hashes])\n",
    "\n",
    "        return cls(train_data), cls(val_data)\n",
    "\n",
    "class PlayoutLoader():\n",
    "    def __init__(self, dataset, batch_size, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.idx = np.arange(len(dataset))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.idx), self.batch_size):\n",
    "            idx = self.idx[i:i+self.batch_size]\n",
    "            # make sure there are at least 4 examples in the batch\n",
    "            if len(idx) >= 4:\n",
    "                yield self.dataset.data[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0.\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.avg:.2e}'\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, in_features, layer0_dims, hidden_dims, hidden_layers, out_features, dropout):\n",
    "        super().__init__()\n",
    "        self._mlist = ModuleList([\n",
    "            Linear(in_features, layer0_dims),\n",
    "            BatchNorm1d(layer0_dims),\n",
    "            ReLU()\n",
    "        ])\n",
    "\n",
    "        in_dim = layer0_dims        \n",
    "        for i in range(hidden_layers):\n",
    "            self._mlist.append(Linear(in_dim, hidden_dims))\n",
    "            self._mlist.append(BatchNorm1d(hidden_dims))\n",
    "            self._mlist.append(ReLU())\n",
    "            self._mlist.append(Dropout(p=dropout))\n",
    "            in_dim = hidden_dims\n",
    "        self._mlist.append(Linear(in_dim, out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self._mlist:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class VorNet(Module):\n",
    "    def __init__(self, input_shape, p_shape, v_shape, policy_layers, policy_l0_dim, policy_dim, value_layers, value_l0_dim, value_dim, dropout):\n",
    "        super(VorNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.p_shape = p_shape\n",
    "        self.v_shape = v_shape\n",
    "        B, F = input_shape\n",
    "\n",
    "        self.input_bn = BatchNorm1d(F)\n",
    "        self.policy_head = MLP(F, policy_l0_dim, policy_dim, policy_layers, 1, dropout)\n",
    "        self.value_head = MLP(4*F, value_l0_dim, value_dim, value_layers, np.prod(self.v_shape), dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, F = x.shape\n",
    "\n",
    "        x = self.input_bn(x.view(B*N, F)).view(B, N, F)\n",
    "\n",
    "        side_nodes = x[:, -4:, :]\n",
    "        x = x.view(B*N, F)\n",
    "        p = self.policy_head(x)\n",
    "        p = p.view(B, np.prod(self.p_shape))\n",
    "        \n",
    "        side_nodes = side_nodes.view(B, 4*F)\n",
    "        v = self.value_head(side_nodes).tanh()\n",
    "\n",
    "        return p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_dist(s, logits, log_softmax=False):\n",
    "    mask = torch.from_numpy(game.get_available_actions(s).astype(np.uint8)).bool()\n",
    "    mask = mask.cuda()\n",
    "    selection = torch.masked_select(logits, mask)\n",
    "    dist = torch.nn.functional.log_softmax(selection, dim=-1)\n",
    "    if log_softmax:\n",
    "        return dist\n",
    "    return torch.exp(dist)\n",
    "\n",
    "def calc_loss(states, prediction, target):\n",
    "    batch_size = len(states)\n",
    "    p_pred, v_pred = prediction\n",
    "    p_gt, v_gt = target\n",
    "    v_gt = torch.from_numpy(v_gt.astype(np.float32))\n",
    "    v_gt = v_gt.cuda()\n",
    "    v_loss = ((v_pred - v_gt)**2).sum() # Mean squared error\n",
    "    p_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        gt = torch.from_numpy(p_gt[i].astype(np.float32))\n",
    "        gt = gt.cuda()\n",
    "        s = states[i]\n",
    "        logits = p_pred[i]\n",
    "        pred = get_valid_dist(s, logits, log_softmax=True)\n",
    "        p_loss += -torch.sum(gt*pred)\n",
    "    return p_loss + v_loss\n",
    "\n",
    "\n",
    "def get_batch_states(batch):\n",
    "    states = np.stack(batch[:,0])\n",
    "    nn_states = [s.nn_attr for s in states]\n",
    "    nn_states = np.stack(nn_states)\n",
    "        \n",
    "    return nn_states, states\n",
    "\n",
    "def train_step(batch, model, optimizer):\n",
    "    model.train()\n",
    "    nn_states, states = get_batch_states(batch)\n",
    "    x = torch.from_numpy(nn_states)\n",
    "    p_pred, v_pred = model(x)\n",
    "    p_gt, v_gt = batch[:,1], np.stack(batch[:,2])\n",
    "    loss = calc_loss(states, (p_pred, v_pred), (p_gt, v_gt))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def val_step(batch, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        nn_states, states = get_batch_states(batch)\n",
    "        x = torch.from_numpy(nn_states)\n",
    "        p_pred, v_pred = model(x)\n",
    "        p_gt, v_gt = batch[:,1], np.stack(batch[:,2])\n",
    "        loss = calc_loss(states, (p_pred, v_pred), (p_gt, v_gt))\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded\n",
      "  34991 train examples\n",
      "  3229 validation examples\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR=\"../checkpoints/train_ex\"\n",
    "EPOCHS=3\n",
    "LR=1e-3\n",
    "WEIGHT_DECAY=1e-4\n",
    "\n",
    "train_ds, val_ds = PlayoutDataset.get_train_val_ds(data_dir=DATA_DIR)\n",
    "print(\"Training data loaded\")\n",
    "print(\"  {} train examples\".format(train_ds.__len__()))\n",
    "print(\"  {} validation examples\".format(val_ds.__len__()))\n",
    "game = Vortex_5()\n",
    "input_shape = game.get_initial_state().shape\n",
    "p_shape = game.get_available_actions(game.get_initial_state()).shape\n",
    "v_shape = (game.get_num_players(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = VorNet(\n",
    "        input_shape, \n",
    "        p_shape, \n",
    "        v_shape,\n",
    "        10, #trial.suggest_int(\"policy_layers\", 1, 15),\n",
    "        trial.suggest_int(\"policy_l0_dim\", 100, 1000),\n",
    "        trial.suggest_int(\"policy_dim\", 100, 1000),\n",
    "        10, #trial.suggest_int(\"value_layers\", 8, 20),\n",
    "        trial.suggest_int(\"value_l0_dim\", 100, 2000),\n",
    "        trial.suggest_int(\"value_dim\", 100, 1000),\n",
    "        trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    )\n",
    "    model = model.to('cuda')\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # weight_decay = lr/10\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", LR/100, LR/2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=weight_decay)\n",
    "\n",
    "    # get the data loaders\n",
    "    #batch_size = trial.suggest_int(\"batch_size\", 8, 256)\n",
    "    batch_size = 256\n",
    "\n",
    "    # Training of the model.\n",
    "    best_loss = None\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loader = PlayoutLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = PlayoutLoader(dataset=val_ds, batch_size=batch_size)\n",
    "        val_loss = AverageMeter()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            train_step(batch, model, optimizer)\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            loss = val_step(batch, model)\n",
    "            val_loss.update(loss / len(batch))\n",
    "\n",
    "        trial.report(val_loss.avg, epoch)\n",
    "        best_loss = val_loss.avg if best_loss is None else min(best_loss, val_loss.avg)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-13 13:51:38,871]\u001b[0m A new study created in memory with name: VorNet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"VorNet\", direction=\"minimize\")\n",
    "# study = joblib.load(\"../checkpoints/train_ex/study.pkl\")\n",
    "# print(\"Best trial until now:\")\n",
    "# print(\" Value: \", study.best_trial.value)\n",
    "# print(\" Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-13 13:53:07,324]\u001b[0m Trial 0 finished with value: 3.0148119407795853 and parameters: {'policy_l0_dim': 976, 'policy_dim': 994, 'value_l0_dim': 553, 'value_dim': 337, 'dropout': 0.1974815212830684, 'weight_decay': 0.00031882260011605897}. Best is trial 0 with value: 3.0148119407795853.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:54:28,423]\u001b[0m Trial 1 finished with value: 3.0233889804757847 and parameters: {'policy_l0_dim': 703, 'policy_dim': 287, 'value_l0_dim': 1540, 'value_dim': 287, 'dropout': 0.33401831156226874, 'weight_decay': 0.00034726991364180206}. Best is trial 0 with value: 3.0148119407795853.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:55:50,975]\u001b[0m Trial 2 finished with value: 3.0189846787366252 and parameters: {'policy_l0_dim': 696, 'policy_dim': 782, 'value_l0_dim': 1539, 'value_dim': 333, 'dropout': 0.35671535907990976, 'weight_decay': 0.0003915886886572914}. Best is trial 0 with value: 3.0148119407795853.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:56:43,943]\u001b[0m Trial 3 finished with value: 3.009603377360447 and parameters: {'policy_l0_dim': 733, 'policy_dim': 939, 'value_l0_dim': 548, 'value_dim': 136, 'dropout': 0.050933659914486173, 'weight_decay': 0.0004114542808649484}. Best is trial 3 with value: 3.009603377360447.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:57:33,221]\u001b[0m Trial 4 finished with value: 3.027079988145057 and parameters: {'policy_l0_dim': 950, 'policy_dim': 326, 'value_l0_dim': 566, 'value_dim': 334, 'dropout': 0.4434561098798667, 'weight_decay': 0.0003916011602909454}. Best is trial 3 with value: 3.009603377360447.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:57:48,913]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:58:03,997]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:58:19,858]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:58:35,561]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 13:59:22,326]\u001b[0m Trial 9 finished with value: 3.006643491302969 and parameters: {'policy_l0_dim': 227, 'policy_dim': 358, 'value_l0_dim': 1897, 'value_dim': 416, 'dropout': 0.07207116350169845, 'weight_decay': 0.00013204407297357366}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:00:17,596]\u001b[0m Trial 10 finished with value: 3.0143957150911125 and parameters: {'policy_l0_dim': 100, 'policy_dim': 562, 'value_l0_dim': 1995, 'value_dim': 946, 'dropout': 0.029660593455326678, 'weight_decay': 0.00019920010267948917}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:01:38,068]\u001b[0m Trial 11 finished with value: 3.0110553958029325 and parameters: {'policy_l0_dim': 367, 'policy_dim': 550, 'value_l0_dim': 973, 'value_dim': 133, 'dropout': 0.004298131082967088, 'weight_decay': 3.169584040928417e-05}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:02:59,015]\u001b[0m Trial 12 finished with value: 3.0080352574805898 and parameters: {'policy_l0_dim': 788, 'policy_dim': 411, 'value_l0_dim': 1056, 'value_dim': 515, 'dropout': 0.12357592889048219, 'weight_decay': 0.000263032970271765}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:03:26,253]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:04:20,870]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:04:48,167]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:06:10,562]\u001b[0m Trial 16 finished with value: 3.0125098122153315 and parameters: {'policy_l0_dim': 840, 'policy_dim': 287, 'value_l0_dim': 835, 'value_dim': 615, 'dropout': 0.10946045429624955, 'weight_decay': 0.00016088959784639587}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:06:37,680]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:07:59,730]\u001b[0m Trial 18 finished with value: 3.0090523144592556 and parameters: {'policy_l0_dim': 464, 'policy_dim': 570, 'value_l0_dim': 1260, 'value_dim': 224, 'dropout': 0.07544177353118287, 'weight_decay': 0.0002495275872641605}. Best is trial 9 with value: 3.006643491302969.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:08:26,865]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:08:54,493]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:09:21,217]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:10:36,126]\u001b[0m Trial 22 finished with value: 3.003438753920522 and parameters: {'policy_l0_dim': 207, 'policy_dim': 487, 'value_l0_dim': 1161, 'value_dim': 232, 'dropout': 0.06039332110765601, 'weight_decay': 0.00031678282755249565}. Best is trial 22 with value: 3.003438753920522.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:10:52,337]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:11:42,138]\u001b[0m Trial 24 finished with value: 3.007163462365509 and parameters: {'policy_l0_dim': 201, 'policy_dim': 339, 'value_l0_dim': 1145, 'value_dim': 233, 'dropout': 0.0006145076428603624, 'weight_decay': 0.0002916530335332173}. Best is trial 22 with value: 3.003438753920522.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:12:29,960]\u001b[0m Trial 25 finished with value: 3.000765025644896 and parameters: {'policy_l0_dim': 205, 'policy_dim': 235, 'value_l0_dim': 1692, 'value_dim': 226, 'dropout': 0.0008681433027716637, 'weight_decay': 0.0003481859455304771}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:13:01,640]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:13:33,436]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:13:49,321]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:14:05,341]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:14:21,115]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:15:36,526]\u001b[0m Trial 31 finished with value: 3.0058024352464767 and parameters: {'policy_l0_dim': 172, 'policy_dim': 334, 'value_l0_dim': 1146, 'value_dim': 206, 'dropout': 0.009035914683820865, 'weight_decay': 0.00029809230302027783}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:16:56,898]\u001b[0m Trial 32 finished with value: 3.003726887737986 and parameters: {'policy_l0_dim': 167, 'policy_dim': 362, 'value_l0_dim': 1890, 'value_dim': 106, 'dropout': 0.023878818030713032, 'weight_decay': 0.00031379974860833116}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:17:23,791]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:17:50,734]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:19:12,733]\u001b[0m Trial 35 finished with value: 3.004611678943512 and parameters: {'policy_l0_dim': 261, 'policy_dim': 150, 'value_l0_dim': 747, 'value_dim': 101, 'dropout': 0.0035095320436668333, 'weight_decay': 0.000424969251012971}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:20:32,465]\u001b[0m Trial 36 finished with value: 3.008950195261102 and parameters: {'policy_l0_dim': 279, 'policy_dim': 181, 'value_l0_dim': 729, 'value_dim': 107, 'dropout': 0.058302835096666374, 'weight_decay': 0.0004171296128097134}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:21:27,280]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:21:55,051]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:23:17,501]\u001b[0m Trial 39 finished with value: 3.007992860559504 and parameters: {'policy_l0_dim': 234, 'policy_dim': 966, 'value_l0_dim': 847, 'value_dim': 140, 'dropout': 0.0006926625278371292, 'weight_decay': 0.0004480433635131548}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:23:44,760]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:24:58,586]\u001b[0m Trial 41 finished with value: 3.007944287066948 and parameters: {'policy_l0_dim': 148, 'policy_dim': 319, 'value_l0_dim': 1160, 'value_dim': 197, 'dropout': 0.01966417833140342, 'weight_decay': 0.0003727885505125784}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:25:46,898]\u001b[0m Trial 42 finished with value: 3.0045940583970605 and parameters: {'policy_l0_dim': 183, 'policy_dim': 237, 'value_l0_dim': 991, 'value_dim': 105, 'dropout': 0.024526978718353548, 'weight_decay': 0.00030914282089654983}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:26:03,627]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:26:19,810]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:26:35,491]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:27:07,838]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:27:23,775]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:28:11,343]\u001b[0m Trial 48 finished with value: 3.004085586562804 and parameters: {'policy_l0_dim': 329, 'policy_dim': 383, 'value_l0_dim': 108, 'value_dim': 156, 'dropout': 0.01991223086317334, 'weight_decay': 0.0002718343234378954}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:28:27,299]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:29:18,830]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:30:39,720]\u001b[0m Trial 51 finished with value: 3.0042071844771003 and parameters: {'policy_l0_dim': 377, 'policy_dim': 156, 'value_l0_dim': 400, 'value_dim': 143, 'dropout': 0.0213244608148633, 'weight_decay': 0.0004988656851671535}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:31:06,634]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:31:33,214]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:32:00,719]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:32:27,991]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:32:54,210]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:33:21,243]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:33:48,441]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:34:16,155]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:34:42,959]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:36:04,578]\u001b[0m Trial 61 finished with value: 3.0061881310912923 and parameters: {'policy_l0_dim': 277, 'policy_dim': 143, 'value_l0_dim': 916, 'value_dim': 129, 'dropout': 7.97002411129892e-05, 'weight_decay': 0.00046794802892995006}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:37:25,399]\u001b[0m Trial 62 finished with value: 3.0058933304315216 and parameters: {'policy_l0_dim': 242, 'policy_dim': 133, 'value_l0_dim': 1061, 'value_dim': 184, 'dropout': 0.014925014791057114, 'weight_decay': 0.0004278345043934819}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:38:46,744]\u001b[0m Trial 63 finished with value: 3.0039682959529013 and parameters: {'policy_l0_dim': 297, 'policy_dim': 224, 'value_l0_dim': 368, 'value_dim': 100, 'dropout': 0.021727974638944134, 'weight_decay': 0.00038332006531272065}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:39:03,449]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:39:52,336]\u001b[0m Trial 65 finished with value: 3.0069309856773647 and parameters: {'policy_l0_dim': 427, 'policy_dim': 254, 'value_l0_dim': 333, 'value_dim': 249, 'dropout': 0.023973307413261324, 'weight_decay': 0.0003042583879133752}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:40:40,909]\u001b[0m Trial 66 finished with value: 3.0025263525352126 and parameters: {'policy_l0_dim': 216, 'policy_dim': 307, 'value_l0_dim': 1797, 'value_dim': 129, 'dropout': 0.06135327776940659, 'weight_decay': 0.0003778371922465342}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:40:57,034]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:41:13,141]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:41:29,109]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:41:45,502]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:42:01,774]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:42:17,514]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:42:52,812]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:43:18,790]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:43:45,436]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:44:12,961]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:44:40,399]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:45:06,756]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:45:33,469]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:46:27,465]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:47:48,405]\u001b[0m Trial 81 finished with value: 3.0070320798274874 and parameters: {'policy_l0_dim': 232, 'policy_dim': 171, 'value_l0_dim': 791, 'value_dim': 111, 'dropout': 0.0018666152032779867, 'weight_decay': 0.0004449875201834685}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:48:15,112]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:49:36,642]\u001b[0m Trial 83 finished with value: 3.0048596187294376 and parameters: {'policy_l0_dim': 208, 'policy_dim': 132, 'value_l0_dim': 100, 'value_dim': 156, 'dropout': 0.008751309687815718, 'weight_decay': 0.00034330413115452735}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:50:04,007]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:50:30,534]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:50:58,784]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:51:52,613]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:52:20,077]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:52:47,308]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:53:08,657]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:53:24,236]\u001b[0m Trial 91 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:53:40,407]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:54:29,167]\u001b[0m Trial 93 finished with value: 3.002853430351283 and parameters: {'policy_l0_dim': 146, 'policy_dim': 152, 'value_l0_dim': 276, 'value_dim': 149, 'dropout': 0.0014037835303181007, 'weight_decay': 0.0003420912535544754}. Best is trial 25 with value: 3.000765025644896.\u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:54:45,518]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:55:01,846]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:55:17,635]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:55:33,540]\u001b[0m Trial 97 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:55:49,241]\u001b[0m Trial 98 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-01-13 14:56:04,720]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  69\n",
      "  Number of complete trials:  31\n",
      "Best trial:\n",
      "  Value:  3.000765025644896\n",
      "  Params: \n",
      "    policy_l0_dim: 205\n",
      "    policy_dim: 235\n",
      "    value_l0_dim: 1692\n",
      "    value_dim: 226\n",
      "    dropout: 0.0008681433027716637\n",
      "    weight_decay: 0.0003481859455304771\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2711986/2555236602.py:2: ExperimentalWarning: plot_param_importances is experimental (supported from v2.2.0). The interface can change in the future.\n",
      "  optuna.visualization.matplotlib.plot_param_importances(study)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Hyperparameter Importances'}, xlabel='Importance for Objective Value', ylabel='Hyperparameter'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#optuna.visualization.matplotlib.plot_contour(study, params=['batch_size', 'lr'])\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../checkpoints/train_ex/study.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, os.path.join(DATA_DIR, \"study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2711986/2112351383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2711986/2984829129.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch, model, optimizer)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mp_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maz/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.vornet import VorNet as _VorNet\n",
    "\n",
    "model = _VorNet(input_shape, p_shape, v_shape)\n",
    "model = model.to('cuda')\n",
    "model = torch.nn.DataParallel(model)\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 5e-4\n",
    "DATA_DIR=\"../checkpoints/train_ex\"\n",
    "\n",
    "log_dir = os.path.join(DATA_DIR, 'logs', str(time()))\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Training of the model.\n",
    "best_loss = None\n",
    "error_log = []\n",
    "for epoch in trange(EPOCHS):\n",
    "    train_loader = PlayoutLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = PlayoutLoader(dataset=val_ds, batch_size=BATCH_SIZE)\n",
    "    train_loss = AverageMeter()\n",
    "    val_loss = AverageMeter()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        loss = train_step(batch, model, optimizer)\n",
    "        train_loss.update(loss / len(batch))\n",
    "    \n",
    "    writer.add_scalar('train loss', train_loss.avg, epoch)\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        loss = val_step(batch, model)\n",
    "        val_loss.update(loss / len(batch))\n",
    "    \n",
    "    writer.add_scalar('val loss', val_loss.avg, epoch)\n",
    "\n",
    "    error_log.append(val_loss)\n",
    "    if (best_loss is None) or (val_loss.avg < best_loss):\n",
    "        best_loss = val_loss.avg       \n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'error_log': error_log,\n",
    "            }, os.path.join(DATA_DIR, \"0.ckpt\"))\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7574f5d857af8f1e8f26ae1ddb33f0e7cd225dc65e7450a2fdad37c59c700f3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('maz': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
